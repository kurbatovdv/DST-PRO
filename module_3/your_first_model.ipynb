{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка Pandas и очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "import workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_task.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 40000 entries, 0 to 39999\nData columns (total 10 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Restaurant_id      40000 non-null  object \n 1   City               40000 non-null  object \n 2   Cuisine Style      30717 non-null  object \n 3   Ranking            40000 non-null  float64\n 4   Rating             40000 non-null  float64\n 5   Price Range        26114 non-null  object \n 6   Number of Reviews  37457 non-null  float64\n 7   Reviews            40000 non-null  object \n 8   URL_TA             40000 non-null  object \n 9   ID_TA              40000 non-null  object \ndtypes: float64(3), object(7)\nmemory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Ваш код по очистке данных и генерации новых признаков\n",
    "# При необходимости добавьте ячейки\n",
    "df.info(max_cols=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 40000 entries, 0 to 39999\nData columns (total 10 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Restaurant_id      40000 non-null  object \n 1   City               40000 non-null  object \n 2   Cuisine Style      30717 non-null  object \n 3   Ranking            40000 non-null  float64\n 4   Rating             40000 non-null  float64\n 5   Price Range        26114 non-null  object \n 6   Number of Reviews  37457 non-null  float64\n 7   Reviews            40000 non-null  object \n 8   URL_TA             40000 non-null  object \n 9   ID_TA              40000 non-null  object \ndtypes: float64(3), object(7)\nmemory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# При необходимости добавьте ячейки\n",
    "df.info(max_cols=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Т.к. в столбце \"Price Range\" больше всего пропуском, используем ссылки из пропущщеных значений дял запросов к сайту.\n",
    "#Получим с сайта Информацию о цене, видах кухни и количестве отзывов, сохраним эту информацию в DataFrame и в файл parse.csv\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    with Pool(processes=40) as pool:\n",
    "#        parse_df = pd.DataFrame(pool.map(workers.make_price, df[df['Price Range'].isna()][\"URL_TA\"]), columns=['Price Range', 'Cuisine Style', 'URL_TA', 'Number of Reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Приведём значения и пропуски к нужным нам типам. так же удалим строки в которых значения нужных нам столбцов пусты\n",
    "parse_df = pd.read_csv('parse.csv', index_col=[\"Unnamed: 0\"])\n",
    "\n",
    "#parse_df.replace(to_replace = {\"Nan\": np.nan}, inplace=True)\n",
    "#parse_df.replace(to_replace = {\"nan\": np.nan}, inplace=True)\n",
    "#parse_df[parse_df[\"Cuisine Style\"].notna()][\"Cuisine Style\"] = parse_df[\"Cuisine Style\"].astype(str)\n",
    "#parse_df.dropna(subset=['Price Range', 'Cuisine Style', 'Number of Reviews'], how=\"all\", inplace=True)\n",
    "parse_df.drop_duplicates(subset=['URL_TA'], inplace=True)\n",
    "#parse_df.to_csv(\"parse.csv\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создадим промежуточный DataFrame и обновим в нём данные полученными с сайта. Так как \n",
    "r = df[df[\"Price Range\"].isna()]\n",
    "r = r.reset_index().set_index(\"URL_TA\")\n",
    "r.update(parse_df.set_index(\"URL_TA\"), overwrite=False)\n",
    "r.set_index(\"index\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[r.index, ['Cuisine Style','Price Range', 'Number of Reviews']] = r[['Cuisine Style','Price Range', 'Number of Reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_dict = {'$': 1, '$$ - $$$': 2.5, '$$$$': 4}\n",
    "df['Price Range'].replace(to_replace = price_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['City'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_city_residents_dict = {'Paris':2148327, 'Stockholm':961609, 'London':8908081, 'Berlin':3644826, 'Munich':1471508, 'Oporto':237591,\n",
    "       'Milan':1378689, 'Bratislava':437725, 'Vienna':1897491, 'Rome':2870500, 'Barcelona':1636762, 'Madrid':3266126,\n",
    "       'Dublin':1173179, 'Brussels':179277, 'Zurich':428737, 'Warsaw':1790658, 'Budapest':1752286, 'Copenhagen':615993,\n",
    "       'Amsterdam':872757, 'Lyon':506615, 'Hamburg':1841179, 'Lisbon':505526, 'Prague':1301132, 'Oslo':673469,\n",
    "       'Helsinki':655281, 'Edinburgh':488100, 'Geneva':200548, 'Ljubljana':284355, 'Athens':664046,\n",
    "       'Luxembourg':602005, 'Krakow':769498}\n",
    "# словарь с кол-вом жителей\n",
    "df['population'] = df['City'].replace(number_city_residents_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rank_on_pop'] = df['Ranking']/df['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAN_Cuisine Style'] = pd.isna(df['Cuisine Style']).astype('float64') \n",
    "cuisine_count = {}\n",
    "for cuisines in df['Cuisine Style'].value_counts().index:\n",
    "    for cuisine in cuisines.strip(\"[]\").replace(\"'\", \"\").split(', '):\n",
    "        if cuisine in cuisine_count:\n",
    "            cuisine_count[cuisine] += 1\n",
    "        else:\n",
    "            cuisine_count[cuisine] = 1\n",
    "\n",
    "df['Cuisine Style'] = df['Cuisine Style'].fillna(\"['Other']\")\n",
    "\n",
    "df['Cuisine Style'] = df['Cuisine Style'].apply(lambda x: len(x.split(',')))\n",
    "\n",
    "def find_item(cell):\n",
    "    if type(cell) == str:\n",
    "        if item in cell:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "for item in cuisine_count.keys():\n",
    "\n",
    "    df[item] = df['Cuisine Style'].apply(find_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "286.1418918918919"
      ]
     },
     "metadata": {},
     "execution_count": 377
    }
   ],
   "source": [
    "sum(cuisine_count.values())/len(cuisine_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "metadata": {},
     "execution_count": 378
    }
   ],
   "source": [
    "len([cuisine for cuisine in cuisine_count.keys() if cuisine_count[cuisine] < 286])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполним пропуски самым частым значением\n",
    "df['NAN_Number of Reviews'] = pd.isna(df['Number of Reviews']).astype('float64') \n",
    "df['Number of Reviews'].fillna(df['Number of Reviews'].mode()[0], inplace = True)\n",
    "df['NAN_Price Range'] = pd.isna(df['Price Range']).astype('float64') \n",
    "df['Price Range'].fillna(df['Price Range'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ВЫделим дату первого и второго отзыва. и заполним пропуски самым частым значенем в каждом столбце\n",
    "def reviews_date(rew, count):\n",
    "    date = re.findall(r'\\d\\d?/\\d\\d?/\\d+', rew)\n",
    "    #print(date, len(date), len(data) == 2)\n",
    "    if len(date) == 0:\n",
    "        return np.nan\n",
    "    if count == 1:\n",
    "        return pd.to_datetime(date[0])\n",
    "    elif len(date) == 2:\n",
    "        return pd.to_datetime(date[1])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df['Reviews_first'] = df['Reviews'].apply(lambda x: reviews_date(x, 1))\n",
    "df['Reviews_second'] = df['Reviews'].apply(lambda x: reviews_date(x, 2))\n",
    "df['Reviews_first'].fillna(df['Reviews_first'].mode()[0], inplace = True)\n",
    "df['Reviews_second'].fillna(df['Reviews_second'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#добавим столбец содержащий количество дней между первым и вторым отзывом\n",
    "df['Reviews_between'] = (df['Reviews_first'] - df['Reviews_second']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разбиваем датафрейм на части, необходимые для обучения и тестирования модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Х - данные с информацией о ресторанах, у - целевая переменная (рейтинги ресторанов)\n",
    "X = df.drop(['City', 'Reviews', 'URL_TA', 'ID_TA', 'Reviews_first', 'Reviews_second', 'Restaurant_id', 'Rating'], axis = 1)\n",
    "y = df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем специальный инструмент для разбивки:\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наборы данных с меткой \"train\" будут использоваться для обучения модели, \"test\" - для тестирования.\n",
    "# Для тестирования мы будем использовать 25% от исходного датасета.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаём, обучаем и тестируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель\n",
    "regr = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# Обучаем модель на тестовом наборе данных\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAE: 0.2141785\n"
     ]
    }
   ],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.21309899999999998"
      ]
     },
     "metadata": {},
     "execution_count": 388
    }
   ],
   "source": [
    "0.21171399999999999\n",
    "0.213905\n",
    "0.2133565\n",
    "0.21309899999999998"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "0a7d32b12258f9fc52bd1add9f093feeb3ae70275521cb87349acee789d16ae1"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}